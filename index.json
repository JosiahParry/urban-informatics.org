[{"categories":[],"contents":"Urban Informatics is a field of study based strictly on the urban environment and more specifically, cities. The urban environment is a very real and physical place. It is not some metaphysical conception that can only be spoken about in broad strokes. There are buildings, roads and intersections, land marks, restaurants and many other physical attributes that make up a city.\nThe city is a place. But when we refer to the city is a place, we are referring to some amorphous geographical boundary which has within it, more places. Boston is a city with clear physical boundaries on it\u0026rsquo;s Eastern and Northern sides\u0026mdash;the Atlantic and the Charles river\u0026mdash;though within it there are further places. There are neighborhoods like the South End and Back Bay which are also places with clearer and distinct boundaries. Within these there are further places like Blackstone Square and the Prudential Centers. These smaller places server a general interest. They can be referred to as land marks and are referenceable with a large degree of accuracy. These types of places are called places of interest.\nPlaces of interest, or POI, are locations that can be accurately located on the map which have some interest to the general public. POI have become increasingly important to the field of urban informatics with companies such as SafeGraph and Foursquare providing place based data. The data can be used to understand land use patterns, street networks, and so much more. Many people are using POI data extensively to understand the coronavirus pandemic (see SafeGraph research here).\nOne of the largest challenges to POI data is that of coverage. How many of the total POIs in a region are actually recorded in a database? How can we be certain that when using POI data that it is accurate? How do we best record changes to the environment when a POI, say restaurant, now longer exists?\nFrom my perspective, there seems to be no cohesive or theoretical definition of a place of interest other than \u0026ldquo;a place of interest.\u0026rdquo; Perhaps the phrase is so simple that it does not need further clarification. But there are still some questions that I suspect need further elaboration. Most pressingly, and this may be a futile line of thought, what actually makes a POI interesting? Seemingly anything maybe a POI and is determined by those who generate or provide the data. The criteria seems that the data must 1) have a coordinate point and 2) be able to described as a place.\nThe Boston Area Research Initiative (BARI) collects Boston based POI data. Among the many data resources they provide are the locations of Boston Airbnbs as provided by Inside Airbnb. These data are used extensively within the Urban Informatics program.\nThe below map utilizes the Airbnb POI data to illustrate spatial distribution and price of Airbnb listings within Boston.\n ","permalink":"/blog/2021-04-26-understanding-places-of-interest/","tags":["POI"],"title":"Understanding Places of Interest"},{"categories":[],"contents":"Overview Tobler\u0026rsquo;s first law of geography states that\n \u0026ldquo;everything is related to everything else, but near things are more related than distant things.\u0026rdquo; - Waldo Tobler (source)\n In regular statistical analyses, we look at the relationship between two variables irrespective of their place in space. If there is a desire to account for space, this will likely be done by creating groups or regional identifiers that can be controlled for in a linear regression. For example, neighborhood or state level dummy variables or IDs.\nWe can move beyond this naive approach to incorporating space into our analysis to something a bit more explicit. We can check to see if there are measurable spatial relationships in our dataset as opposed to strictly measuring numeric correlation.\nThis post will introduce the concept of spatial autocorrelation. First we will create a dataset to work with. Then we\u0026rsquo;ll review neighbors, weights, and autocorrelation.\nCreating our dataset In this analysis, we will explore the spatial relationship of bachelor\u0026rsquo;s degree attainment in Suffolk County (Greater Boston). The data we will be using comes from the Urban Informatics Toolkit\u0026rsquo;s associate package {uitk}. This can be installed with remotes::install_github(\u0026quot;josiahparry/uitk\u0026quot;).\nThe package exports acs_raw which is a tibble containing socio-economic and demographic characteristics from the American Community Survey (ACS) as provided by the Boston Area Research Initiative (BARI). From the tibble, we\u0026rsquo;ll select a few variables to explore throughout. These are the median household income (med_house_income), proportion of the population that uses public transit (by_pub_trans), proportion of the population with a bachelor\u0026rsquo;s degree (bach), and then FIPS code. Additionally, there are a few missing values in our variables. We\u0026rsquo;ll fill those in with median imputation.\nThe object suffolk_county contains the boundary of each census tract and will be joined to the ACS data.\nlibrary(sf) library(tidyverse) acs \u0026lt;- select(uitk::acs_raw, fips = ct_id_10, med_house_income, by_pub_trans, bach) %\u0026gt;% mutate(fips = as.character(fips), across(.cols = c(med_house_income, by_pub_trans, bach), ~replace_na(.x, median(.x, na.rm = TRUE)))) acs_sf \u0026lt;- left_join(uitk::suffolk_county, acs, by = \"fips\")  Now that we have this object we can visualize how median household income is distributed numerically and geographically.\nacs_sf %\u0026gt;% ggplot(aes(bach)) + geom_histogram(bins = 15, fill = \"#528672\") + theme_minimal() + geom_vline(aes(xintercept = mean(bach)), lty = 3, size = .75) + labs(x = \"Median Household Income\", y = \"Frequency\", title = \"Distribution of Educational Attainment\")   acs_sf %\u0026gt;% mutate(bach_dec = ntile(bach, 10)) %\u0026gt;% ggplot(aes(fill = bach_dec)) + geom_sf(lwd = 0.2, color = \"black\") + theme_void() + scale_fill_gradient(high = \"#528672\", n.breaks = 10) + labs(title = \"Educational Attainment Deciles\")   From the graph and map we can see two things:\n The distribution of educational attainment is left skewed There appears to be clusters of low educational attainment in the north and the south  How can we check to see if there is a significant spatial relationship? We\u0026rsquo;ll need to look at the surrounding values of each observation.\nUnderstanding spatial autocorrelation Typical correlation measures explores how two continuous variables are related to each other. Does one increase when the other does? Spatial autocorrelation looks to see if a variable has any relationship in how it is distributed across a geography. With spatial autocorrelation we can ask the question \u0026ldquo;are like values near each other?\u0026rdquo; With measures of spatial auto correlation we can only know if similar values cluster near each other. Or, inversely, near values are different from each other and far ones are similar.\nThe most common measure of spatial autocorrelation is Moran\u0026rsquo;s I. Moran\u0026rsquo;s I is a number that typically ranges between -1 and 1 much like other correlation measures. Though Moran\u0026rsquo;s I can exceed either boundary in some rare cases.\nWhen I approaches 1, we can interpret Moran\u0026rsquo;s I as informing us that similar values tend to be nearby each other. When I approach -1, near values are dissimilar. We cannot determine whether the clusters are positively or negatively associated, though!\nUnderstanding neighbors If we assume that there is a spatial relationship in our data, we are taking on the belief that our data are not completely independent of each other. If nearer things are more related, then census tracts that are close to each other will have similar values. In the urban literature there is a lot of discussion of \u0026ldquo;spillover effects.\u0026quot; A spillover effect is when a change in one neighborhood affects adjacent / nearby neighborhoods. This is in essence what we are trying to evaluate.\nBecause we are concerned with what surrounding observations look like, we need to know which observations are nearby. There are a number of different ways in which neighbors can be identified. With polygon data we identify neighbors based on their contiguity. To be contiguous means to be connected or touching\u0026mdash;think of the contiguous lower 48 states.\nContiguities The two most common contiguities are based on the game of chess. Let\u0026rsquo;s take a simple chess board (code included because it\u0026rsquo;s a fun trick ðŸ˜„).\nchess_board \u0026lt;- expand.grid(x = 1:8, y = 1:8) %\u0026gt;% mutate(z = ifelse((x + y) %% 2 == 0, TRUE, FALSE)) board \u0026lt;- chess_board %\u0026gt;% ggplot(aes(x, y, fill = z)) + geom_tile() + scale_fill_manual(values = c(\"white\", \"black\")) + theme_void() + coord_fixed() + theme(legend.position = \"none\") board   In chess each piece can move in a different way. All pieces, with the exception of the knight, move either diagonally or horizontally and vertically. The most common contiguities are queen and rook contiguities. In chess, a queen can move diagonally and horizontal and vertically whereas a rook can only move horizontal and vertically.\n We extend this idea to polygons. Queen contiguities identify neighbors based on any polygon that is touching. With rook contiguities, we identify neighbors based on polygons that touch on the side. For most social science research, we only need to be concerned with queen contiguities.\n While a chess board might make intuitive sense, geographies are really wonky in real life. Let\u0026rsquo;s take a random census tract in Suffolk County and look at its queen contiguity.\n You can see that any tract that is touching, even at a corner, will be considered a neighbor to the point in question. This will be done for every polygon in our dataset. We can create a network diagram of our spatial object which can be helpful or exploring these spatial relationships visually and encourage a network based approach.\n Understanding the spatial weights Once neighbors are identified, they can then be used to calculate spatial weights. These weights will be used to identify the average local household income for surrounding census tracts. However, prior to doing so, we must know how much influence each observation will have in calculating that local estimate.\nThe typical method of calculating the spatial weights is through row standardization. In essence, each neighbor that touches our census tract will be assigned an equal weight. We do this by assigning each neighbor a value of 1 then dividing by the number of neighbors. So if we have 5 neighboring census tracts, each of them will have a spatial weight of 0.2 (1 / 5 = 0.2).\nGoing back to the chess board example, we can take the position d4 and look at the queen contiguities. There are 8 squares that immediately touch the square. Each one of these squares is considered a neighbor and given a value of 1. Then each square is divided by the total number or neighbors, 8.\n Very simply it looks like the following\n(d4_nbs \u0026lt;- rep(1, 8)) #\u0026gt; [1] 1 1 1 1 1 1 1 1 d4_nbs / length(d4_nbs) #\u0026gt; [1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125  Defining neighbor relationships Now that we have a general understanding of neighbors and weights we can go ahead and and begin to create do the work in R. For this we will use the package sfweight. Currently the package is not on CRAN and needs to be installed from GitHub. Install the package with the following: remotes::install_github(\u0026quot;josiahparry/sfweight\u0026quot;).\nThere are two functions that we will be using from this package: st_neighbors() and st_weights(). The former will take the geometry column of an sf object and create a list column containing the neighbor indexes for that observation. st_weights() will take the neighbors list and calculate a list column of weights. These functions work nicely with the tidyverse workflow so we can calculate both the neighbors and weights in one mutate function call.\nlibrary(sfweight) acs_nbs \u0026lt;- acs_sf %\u0026gt;% mutate(nb = st_neighbors(geometry), wt = st_weights(nb))  It was easy as that. We can look at the neighbor and weights columns. Notice how they are always of the same length for each row.\nNeighbors list:\npull(acs_nbs, nb)[1:5] #\u0026gt; [[1]] #\u0026gt; [1] 2 15 168 171 172 179 180 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] 1 71 180 #\u0026gt;  #\u0026gt; [[3]] #\u0026gt; [1] 45 50 92 122 #\u0026gt;  #\u0026gt; [[4]] #\u0026gt; [1] 30 84 127 135 136 138 #\u0026gt;  #\u0026gt; [[5]] #\u0026gt; [1] 34 87 100 108  Weights list:\npull(acs_nbs, wt)[1:5] #\u0026gt; [[1]] #\u0026gt; [1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 #\u0026gt;  #\u0026gt; [[2]] #\u0026gt; [1] 0.3333333 0.3333333 0.3333333 #\u0026gt;  #\u0026gt; [[3]] #\u0026gt; [1] 0.25 0.25 0.25 0.25 #\u0026gt;  #\u0026gt; [[4]] #\u0026gt; [1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 #\u0026gt;  #\u0026gt; [[5]] #\u0026gt; [1] 0.25 0.25 0.25 0.25  Measuring spatial autocorrelation With all of our measures in place, we can calculate Moran\u0026rsquo;s I and check to see if there is any spatial autocorrelation.\nacs_nbs %\u0026gt;% moran_test(bach, nb, wt) #\u0026gt;  #\u0026gt; Moran I test under randomisation #\u0026gt;  #\u0026gt; data: var  #\u0026gt; weights: listw  #\u0026gt;  #\u0026gt; Moran I statistic standard deviate = 14.037, p-value \u0026lt; 2.2e-16 #\u0026gt; alternative hypothesis: greater #\u0026gt; sample estimates: #\u0026gt; Moran I statistic Expectation Variance  #\u0026gt; 0.596022182 -0.004950495 0.001833067  With this result we can tell that there is a somewhat strong spatial relationship in bachelor\u0026rsquo;s degree attainment throughout Suffolk County. To explore where these clusters are we can use the local Moran\u0026rsquo;s I. This will be covered in a forth coming post.\nMiscellaneous Resources  resource: https://spatiolog.blogspot.com/2019/01/contiguity-based-spatial-weights-matrix.html https://www.e-education.psu.edu/geog586/node/672#:~:text=The%20Moran%20scatterplot%20is%20an,same%20attribute%20at%20neighboring%20locations. https://geographicdata.science/book/notebooks/07_local_autocorrelation.html https://rspatial.org/raster/analysis/3-spauto.html http://www.dpi.inpe.br/gilberto/tutorials/software/geoda/tutorials/w8_weights.pdf  ","permalink":"/tutorials/2021-05-07-spatial-autocorrelation-in-r/","tags":[],"title":"Spatial Autocorrelation in R"},{"categories":[],"contents":"A paper summary in 500ish words  \u0026ldquo;political conflict over LULUs is a struggle between capital and community via the intermediary of the state.\u0026rdquo;\n \n Cartoon by Luke McGarry \nIn order to understand the rising YIMBY movement, we need to first understand its progenitor, NIMBY. There is no better paper to start at than \u0026ldquo;Rethinking NIMBY\u0026rdquo; by Robert W. Lake (1993). In this paper Lake introduces us to the common conception of NIMBY, his nuanced view of NIMBY in relation to capitalism, and the necessary political process which creates the NIMBY movement. The paper may be more aptly titled \u0026ldquo;In Defense of NIMBY.\u0026rdquo;\nNIMBY, or Not In My Back Yard, is an opposition movement to unwanted development of locally unwanted land uses (LULU). LULUs are places like landfills, roads, recovery centers and the like which have some societal benefit. NIMBY is often thought to be \u0026ldquo;selfish\u0026rdquo; and \u0026ldquo;parochial\u0026rdquo; given these proposed developments serve some good\u0026mdash;we all need roads, right? NIMBY has been a surprising success in thwarting developments in favor of \u0026ldquo;neighborhood ambiance.\u0026rdquo;\nLake challenges general antipathy towards NIMBY by addressing a problematic understanding of LULUs. Those who oppose NIMBY make the assumption that LULUs provide a societal good. But what Lake points out is that they are a \u0026ldquo;particular solution to a problem.\u0026rdquo; Acceptance of LULUs accepts the status quo and assumes that there couldn\u0026rsquo;t be a better solution to the problem.\nLake then points out that NIMBY is actually an inevitability and a sign of successful developments. Think of development like creating a product to sell. You need to have customers. In order to produce the product, you need investors who believe there will be profit. The same is true with development. Private investors build to a target consumer base to ensure future profit. Then people move in or start utilizing the developments creating a land use pattern. The development\u0026mdash;say multifamily homes with local markets and cafÃ©s\u0026mdash;will develop their own problems such as \u0026ldquo;low-density development, suburban sprawl, [and] inadequate services.\u0026rdquo;\nWe come to two challenges: 1) current consumers of the existing land use want to maintain the status quo. And 2) changes to the land use would be beneficial to investors to increase their profitability. Proposed changes to the land use are likely against NIMBY best interest but are in the best interest of private industry.\nThe propositions by private industry are not always in the interest of the existing neighborhood or in the best interest of society. Lake provides the example of hazardous waste incinerators. Hazardous waste is that, hazardous. Over a span of 15 years NIMBY collective action prevented a single incinerator from being built. Through this example we see that NIMBY can be an effective movement in challenging existing social structures.\nThus, we come to the conclusion that \u0026ldquo;local community perspective is not necessarily opposed to the societal good\u0026mdash;but nor is it necessarily synonymous with it.\u0026rdquo; Or more simply, the NIMBY movement can be helpful in challenging private industry and government to address the underlying issues that LULUs are meant to address.\n","permalink":"/blog/2021-04-25-rethinking-nimby/","tags":[],"title":"Rethinking NIMBY"},{"categories":[],"contents":"The urban data collective is an opportunity to create an publication that is solely focused on urban informatics. It is borne borne out of a desire to create an easy and non-academic resource for folks interested in or entering urban informtics. Most, if not all, resources and sites dedicated to the topic in the field are jargon heavy or overly academic. Our intention is to produce content that is engaging, consumable, and above all else, useful.\nAs it is entitled a collective, we would like to see contributions from the community. If you woud like to contribute a blog post or a tutorial, please create an issue on the github repository.\n","permalink":"/blog/2021-04-11-introducing-the-urban-collective/","tags":[],"title":"Introducing the urban data collective"},{"categories":["covid-19"],"contents":"  Studying Covid-19â€™s Effect on Community Vulnerability in Massachusetts The Covid-19 crisis has exposed the weak hidden foundations upon which our â€˜prosperousâ€™ society was built, and exacerbated visible ones. The most visible of these factors is the sudden jump in unemployment over the summer. This project aims to develop a â€˜Community Vulnerability Indexâ€™ to understand the devastating effects the health and economic crisis brought on by the Covid-19 pandemic. It aims to identify communities in Massachusetts most affected by heightened unemployment during the summer for targeted relief and developmental assistance.\n  Slide Comments     Project Cover   Data Sources and Index Development   Summer Unemployment Rates   R Code Development   R Code Development   Index Mapped   Top 10 Worst Hit   Top 10 Least Hit   Detailed Factor Analysis   Policy Recommendations     ","permalink":"/blog/2021-04-11-a-state-of-being/","tags":[],"title":"A State of Being"}]